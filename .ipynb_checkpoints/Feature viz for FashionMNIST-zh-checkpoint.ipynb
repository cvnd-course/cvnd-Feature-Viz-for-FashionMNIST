{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将CNN各层可视化\n",
    "---\n",
    "在这个notebook中，我们要加载一个已训练的CNN（从解决方案到FashionMNIST），并实现几种特征可视化技术，从而了解该网络已经学会了提取哪些特征。\n",
    "\n",
    "### 加载 [数据](http://pytorch.org/docs/stable/torchvision/datasets.html) \n",
    "\n",
    "在这个单元格中，我们只加载FashionMNIST类中的**测试**数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our basic libraries\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# data loading and transforming\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors for input into a CNN\n",
    "\n",
    "## Define a transform to read the data in as a tensor\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "test_data = FashionMNIST(root='./data', train=False,\n",
    "                                  download=True, transform=data_transform)\n",
    "\n",
    "\n",
    "# Print out some stats about the test data\n",
    "print('Test data, number of images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test data, number of images:  10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders, set the batch_size\n",
    "## TODO: you can try changing the batch_size to be larger or smaller\n",
    "## when you get to training your network, see how batch_size affects the loss\n",
    "batch_size = 20\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将一些测试数据可视化\n",
    "\n",
    "该单元格会遍历该训练数据集，并使用`dataiter.next()`加载一个随机批次的图像/标签数据。然后，它会在`2 x batch_size/2`网格中将这批图像和标签可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_5_0.png)\n",
    "\n",
    "\n",
    "### 定义网络架构\n",
    "\n",
    " [这里](http://pytorch.org/docs/stable/nn.html)记录了构成任何一种神经网络所需的各个层。对于卷积神经网络，我们将使用下列几个简单的层：\n",
    "* 卷积层\n",
    "* 最大池化层\n",
    "* 全连接层（线性层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 1 input image channel (grayscale), 10 output channels/feature maps\n",
    "        # 3x3 square convolution kernel\n",
    "        ## output size = (W-F)/S +1 = (28-3)/1 +1 = 26\n",
    "        # the output Tensor for one image, will have the dimensions: (10, 26, 26)\n",
    "        # after one pool layer, this becomes (10, 13, 13)\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        \n",
    "        # maxpool layer\n",
    "        # pool with kernel_size=2, stride=2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # second conv layer: 10 inputs, 20 outputs, 3x3 conv\n",
    "        ## output size = (W-F)/S +1 = (13-3)/1 +1 = 11\n",
    "        # the output tensor will have dimensions: (20, 11, 11)\n",
    "        # after another pool layer this becomes (20, 5, 5); 5.5 is rounded down\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        \n",
    "        # 20 outputs * the 5*5 filtered/pooled map size\n",
    "        self.fc1 = nn.Linear(20*5*5, 50)\n",
    "        \n",
    "        # dropout with p=0.4\n",
    "        self.fc1_drop = nn.Dropout(p=0.4)\n",
    "        \n",
    "        # finally, create 10 output channels (for the 10 classes)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    # define the feedforward behavior\n",
    "    def forward(self, x):\n",
    "        # two conv/relu + pool layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # prep for linear layer\n",
    "        # this line of code is the equivalent of Flatten in Keras\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # two linear layers with dropout in between\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # final output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载已训练的网络\n",
    "\n",
    "这个notebook需要知道之前定义的网络架构，知道“Net”类的外观后，我们就可以实例化一个模型并在已训练的网络中进行加载。\n",
    "\n",
    "上面的网络架构取自示例解决方案代码，该代码已经过训练并保存在目录`saved_models/`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate your Net\n",
    "net = Net()\n",
    "\n",
    "# load the net parameters by name\n",
    "net.load_state_dict(torch.load('saved_models/fashion_net_ex.pt'))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net(\n",
    "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=500, out_features=50, bias=True)\n",
    "  (fc1_drop): Dropout(p=0.4)\n",
    "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征可视化\n",
    "\n",
    "有时，神经网络会被当做是一个黑盒子，给定一些输入，它就会学习产生一些输出。 事实上，CNN正在学习识别各种空间模式，你可以通过查看构成每个卷积核的权重并将这些权重一次性应用于样本图像来可视化每个卷积层已被训练识别的内容。这种技术称为特征可视化，它对于理解CNN的内部工作方式来说很有帮助。\n",
    "\n",
    "在下面的单元格中，你将要看到如何提取和可视化第一个卷积层中所有滤波器的滤波权重。\n",
    "\n",
    "请注意亮像素和暗像素的模式，看看是否可以判断特定滤波检测到的是什么。例如，下面示例中所示的滤波在任一侧都有暗像素，在中间列中有亮像素，因此可能会检测到垂直边缘。\n",
    "\n",
    "<img src='edge_filter_ex.png' width= 30% height=30%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights in the first conv layer\n",
    "weights = net.conv1.weight.data\n",
    "w = weights.numpy()\n",
    "\n",
    "# for 10 filters\n",
    "fig=plt.figure(figsize=(20, 8))\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(0, columns*rows):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(w[i][0], cmap='gray')\n",
    "    \n",
    "print('First convolutional layer')\n",
    "plt.show()\n",
    "\n",
    "weights = net.conv2.weight.data\n",
    "w = weights.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First convolutional layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_11_1.png)\n",
    "\n",
    "\n",
    "### 激活映射图\n",
    "\n",
    "接下来，你将要看到的是如何使用OpenCV的`filter2D`函数将这些滤波器应用于示例测试图像，并生成一系列**激活映射图**。我们将对第一个和第二个卷积层执行此操作，这些激活映射图可以让你真正了解每个滤波器学习提取的特征有哪些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of testing images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# select an image by index\n",
    "idx = 3\n",
    "img = np.squeeze(images[idx])\n",
    "\n",
    "# Use OpenCV's filter2D function \n",
    "# apply a specific set of filter weights (like the one's displayed above) to the test image\n",
    "\n",
    "import cv2\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "weights = net.conv1.weight.data\n",
    "w = weights.numpy()\n",
    "\n",
    "# 1. first conv layer\n",
    "# for 10 filters\n",
    "fig=plt.figure(figsize=(30, 10))\n",
    "columns = 5*2\n",
    "rows = 2\n",
    "for i in range(0, columns*rows):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    if ((i%2)==0):\n",
    "        plt.imshow(w[int(i/2)][0], cmap='gray')\n",
    "    else:\n",
    "        c = cv2.filter2D(img, -1, w[int((i-1)/2)][0])\n",
    "        plt.imshow(c, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_13_0.png)\n",
    "\n",
    "\n",
    "\n",
    "![png](output_13_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same process but for the second conv layer (20, 3x3 filters):\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "# second conv layer, conv2\n",
    "weights = net.conv2.weight.data\n",
    "w = weights.numpy()\n",
    "\n",
    "# 1. first conv layer\n",
    "# for 20 filters\n",
    "fig=plt.figure(figsize=(30, 10))\n",
    "columns = 5*2\n",
    "rows = 2*2\n",
    "for i in range(0, columns*rows):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    if ((i%2)==0):\n",
    "        plt.imshow(w[int(i/2)][0], cmap='gray')\n",
    "    else:\n",
    "        c = cv2.filter2D(img, -1, w[int((i-1)/2)][0])\n",
    "        plt.imshow(c, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_14_0.png)\n",
    "\n",
    "\n",
    "\n",
    "![png](output_14_1.png)\n",
    "\n",
    "\n",
    "### 问题：从已训练的卷积层中选择一个滤波器，然后看一看这些激活映射图，你认为这个滤波器会起到什么作用？你认为它会检测到哪种特征？\n",
    "\n",
    "\n",
    "**答案**: 在第一个卷积层（conv1）中，第一个滤波器（如左上角网格角中所示）似乎检测到了水平边缘。它有一个负加权的顶行和正加权的中间行和最底部的行，似乎可以检测到套衫中袖子的水平边缘。\n",
    "\n",
    "在第二个卷积层（conv2）中，第一个滤波器看起来可能检测到了背景颜色（因为这是滤波图像中最亮的区域）和套头衫的垂直边缘。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
